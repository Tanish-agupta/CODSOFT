import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV
from sklearn.preprocessing import OneHotEncoder, StandardScaler, SimpleImputer
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.ensemble import RandomForestClassifier
import os

# Read the data
titanic_data = pd.read_csv("C:/Users/lenovo/Desktop/data/train.csv")

# Convert non-numeric columns to numeric using Label Encoding
label_encoder = LabelEncoder()
for column in titanic_data.columns:
    if titanic_data[column].dtype == 'object':
        titanic_data[column] = label_encoder.fit_transform(titanic_data[column])

# Use StratifiedShuffleSplit to create training and test sets
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_indices, test_indices in split.split(titanic_data, titanic_data[["Survived", "Pclass", "Sex"]]):
    strat_train_set = titanic_data.loc[train_indices]
    strat_test_set = titanic_data.loc[test_indices]

# Display correlation heatmap
sns.heatmap(titanic_data.corr(), cmap="viridis")
plt.show()

# Custom transformers for the pipeline
class AgeImputer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        imputer = SimpleImputer(strategy="mean")
        X["Age"] = imputer.fit_transform(X[['Age']])
        return X

class FeatureEncoder(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        encoder = OneHotEncoder()
        for feature in ['Embarked', 'Sex']:
            matrix = encoder.fit_transform(X[[feature]]).toarray()
            column_names = encoder.get_feature_names_out([feature])
            for i, col_name in enumerate(column_names):
                X[col_name] = matrix[:, i]
        return X

class FeatureDropper(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        return X.drop(["Embarked", "Name", "Ticket", "Cabin", "Sex"], axis=1, errors="ignore")

# Define the pipeline
pipeline = Pipeline([
    ("ageimputer", AgeImputer()),
    ("featureencoder", FeatureEncoder()),
    ("featuredropper", FeatureDropper())
])

# Apply pipeline to training set
strat_train_set = pipeline.fit_transform(strat_train_set)

# Prepare data for model training
X_train = strat_train_set.drop('Survived', axis=1)
y_train = strat_train_set['Survived']

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)

# Define the classifier and grid search parameters
clf = RandomForestClassifier(random_state=42)
param_grid = {
    "n_estimators": [10, 100, 200, 500],
    "max_depth": [None, 5, 10],
    "min_samples_split": [2, 3, 4]
}
grid_search = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy')
grid_search.fit(X_train_scaled, y_train)

# Evaluate on test set
strat_test_set = pipeline.transform(strat_test_set)
X_test = strat_test_set.drop('Survived', axis=1)
y_test = strat_test_set['Survived']
X_test_scaled = scaler.transform(X_test)

# Calculate test score
test_score = grid_search.best_estimator_.score(X_test_scaled, y_test)

# Load new test data
titanic_test_data = pd.read_csv("C:/Users/lenovo/Desktop/data/test.csv")

# Prepare and scale features
final_test_data = pipeline.transform(titanic_test_data)
X_final_test_scaled = scaler.transform(final_test_data)

# Make predictions
predictions = grid_search.best_estimator_.predict(X_final_test_scaled)

# Create a DataFrame for saving predictions
final_df = pd.DataFrame({
    'PassengerId': titanic_test_data['PassengerId'],
    'Survived': predictions
})

# Print out the DataFrame to check its content
print(final_df.head())

# Define the directory path
directory = "C:/Users/lenovo/Desktop/data/"

# Check if the directory exists, if not, create it
if not os.path.exists(directory):
    os.makedirs(directory)

# Save the DataFrame to a CSV file
final_df.to_csv(directory + "predictions.csv", index=False)

# Print a message to indicate that the file has been saved
print("Predictions saved to:", directory + "predictions.csv")
